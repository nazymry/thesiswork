{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#first we import all the necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_curve, auc, confusion_matrix, precision_recall_curve\n",
    ")\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import BatchNorm1d\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "#proving brownish/beige palette for non topology plots in order to match with our paper colours\n",
    "PALETTE = {\n",
    "    'dark':   '#8b4513',  \n",
    "    'med':    '#deb887',  \n",
    "    'light':  '#f5deb3',  \n",
    "    'accent': '#cd853f'   \n",
    "}\n",
    "\n",
    "#label encoding\n",
    "def load_attack_type(data_dir, attack_type, nrows=10000, n_attacks=20, amount_of_noise=0.3):\n",
    "    path = os.path.join(data_dir, f\"{attack_type}.csv\")\n",
    "    df = pd.read_csv(path, nrows=nrows, low_memory=False)\n",
    "    df.columns = df.columns.str.strip()  #removing extra spaces in headers\n",
    "    df['attack_type'] = attack_type      \n",
    "    df['Label'] = df['Label'].map(lambda x: 0 if 'benign' in str(x).lower() else 1)\n",
    "\n",
    "    attack_df = df[df['Label'] == 1].copy()  #attack flows\n",
    "    benign_df = df[df['Label'] == 0].copy()  #benign flows\n",
    "\n",
    "    if not attack_df.empty:\n",
    "        generated = []\n",
    "        for i in range(1, n_attacks + 1):\n",
    "            fake_ip = f\"10.10.10.{i}\"\n",
    "            rows = attack_df.sample(frac=0.3, replace=True, random_state=i).copy()\n",
    "            rows['Source IP'] = fake_ip\n",
    "\n",
    "            #gaussian noise to numeric features \n",
    "            num_cols = rows.select_dtypes(include=[np.number]).columns.difference(['Label'])\n",
    "            for col in num_cols:\n",
    "                vals = rows[col].dropna()\n",
    "                std_dev = vals.std(ddof=0) if len(vals) > 0 else 0\n",
    "                sigma = amount_of_noise * std_dev if std_dev > 0 else 1\n",
    "                rows[col] += np.random.normal(0, sigma, size=rows.shape[0])\n",
    "\n",
    "            #flipping some labels back to benign\n",
    "            if i % 5 == 0:\n",
    "                rows['Label'] = 0\n",
    "\n",
    "            generated.append(rows)\n",
    "\n",
    "        attack_df = pd.concat([attack_df] + generated, ignore_index=True)\n",
    "\n",
    "    df = pd.concat([benign_df, attack_df], ignore_index=True)\n",
    "    return df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "#placeholder for any df cleaning steps\n",
    "def preprocess_for_graph(df):\n",
    "    return df\n",
    "\n",
    "#convertinh flow dataframe into a torch_geometric data object\n",
    "def build_graph(flow_df):\n",
    "    #replacing inf and nans with 0s\n",
    "    flow_df = flow_df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "    #mapping each ip to a unique node index\n",
    "    ip_set = pd.unique(flow_df[['Source IP', 'Destination IP']].values.ravel())\n",
    "    ip_map = {ip: idx for idx, ip in enumerate(ip_set)}\n",
    "    rev_map = {idx: ip for ip, idx in ip_map.items()}\n",
    "\n",
    "    flow_df['src'] = flow_df['Source IP'].map(ip_map)\n",
    "    flow_df['dst'] = flow_df['Destination IP'].map(ip_map)\n",
    "\n",
    "    #building node feature matrix by avg numeric cols per node\n",
    "    num_cols = flow_df.select_dtypes(include=[np.number]).columns.difference(['src', 'dst', 'Label'])\n",
    "    node_features = []\n",
    "    for node in range(len(ip_set)):\n",
    "        sub = flow_df[flow_df['src'] == node]\n",
    "        feat = sub[num_cols].mean().values if not sub.empty else np.zeros(len(num_cols))\n",
    "        node_features.append(feat)\n",
    "    node_df = pd.DataFrame(node_features, columns=num_cols).fillna(0)\n",
    "\n",
    "    #edge_index/edge_attr tensors\n",
    "    edge_index = torch.tensor(flow_df[['src', 'dst']].values.T, dtype=torch.long)\n",
    "    edge_attr = torch.tensor(\n",
    "        StandardScaler().fit_transform(flow_df['Flow Bytes/s'].values.reshape(-1, 1)),\n",
    "        dtype=torch.float\n",
    "    )\n",
    "    x = torch.tensor(StandardScaler().fit_transform(node_df), dtype=torch.float)\n",
    "\n",
    "    #labeling nodes as attack if any incident flow has Label=1\n",
    "    attack_nodes = np.union1d(\n",
    "        flow_df[flow_df['Label'] == 1]['src'].unique(),\n",
    "        flow_df[flow_df['Label'] == 1]['dst'].unique()\n",
    "    )\n",
    "    y = torch.tensor([1 if i in attack_nodes else 0 for i in range(len(node_df))], dtype=torch.float)\n",
    "\n",
    "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "    data.node_ip_map = rev_map             #mapping back to IP\n",
    "    data.raw_flows = flow_df               #keeping raw flow df for plotting\n",
    "    data.feature_names = list(num_cols)    #we save feature names for importance\n",
    "    data.time_series = flow_df[['Timestamp', 'Flow Bytes/s']] \\\n",
    "        if 'Timestamp' in flow_df.columns else None\n",
    "    return data\n",
    "\n",
    "#defining gnn model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.3, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return torch.sigmoid(x).squeeze()\n",
    "\n",
    "#training\n",
    "def train(data, epochs, hidden_channels=32):\n",
    "    model = GCN(data.x.shape[1], hidden_channels)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    loss_fn = torch.nn.BCELoss()\n",
    "    for _ in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = loss_fn(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model\n",
    "\n",
    "#metrics evaluation\n",
    "def evaluate_model(model, data, threshold=0.5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        scores = model(data).numpy()\n",
    "        true = data.y.numpy()\n",
    "        pred = (scores > threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(true, pred)\n",
    "    prec = precision_score(true, pred, zero_division=0)\n",
    "    rec = recall_score(true, pred, zero_division=0)\n",
    "    f1 = f1_score(true, pred, zero_division=0)\n",
    "    tn, fp, fn, tp = confusion_matrix(true, pred).ravel()\n",
    "    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "\n",
    "    print(f\"tp: {tp}, fp: {fp}, tn: {tn}, fn: {fn}\")\n",
    "    print(f\"accuracy: {acc:.4f}, precision: {prec:.4f}, recall: {rec:.4f}, f1: {f1:.4f}\")\n",
    "    print(f\"tpr: {tpr:.4f}, fpr: {fpr:.4f}\")\n",
    "\n",
    "    return true, scores, pred, acc, prec, rec, f1, tp, fp, tn, fn\n",
    "\n",
    "#plot feature importances \n",
    "def plot_feature_importance(model, data, pdf):\n",
    "    model.eval()\n",
    "    x = data.x.clone().detach().requires_grad_(True)\n",
    "    with torch.enable_grad():\n",
    "        out = model(Data(x=x, edge_index=data.edge_index))\n",
    "        out.mean().backward()\n",
    "    grads = x.grad.abs().mean(dim=0).numpy()\n",
    "    names = data.feature_names\n",
    "    imp = sorted(zip(names, grads), key=lambda z: z[1], reverse=True)[:10]\n",
    "    top_names, top_grads = zip(*imp)\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.barh(top_names[::-1], top_grads[::-1], color=PALETTE['med'])\n",
    "    plt.title(\"top10 feature importances\")\n",
    "    plt.xlabel(\"avg gradient magnitude\")\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig(); plt.close()\n",
    "\n",
    "#roc and precision recall curves\n",
    "def plot_roc_pr(y_true, y_scores, pdf):\n",
    "    fpr_vals, tpr_vals, _ = roc_curve(y_true, y_scores)\n",
    "    auc_val = auc(fpr_vals, tpr_vals)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr_vals, tpr_vals, color=PALETTE['dark'], label=f\"auc={auc_val:.2f}\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=PALETTE['light'])\n",
    "    plt.xlabel(\"fpr\"); plt.ylabel(\"tpr\"); plt.title(\"roc curve\"); plt.legend()\n",
    "    pdf.savefig(); plt.close()\n",
    "\n",
    "    prec_vals, rec_vals, _ = precision_recall_curve(y_true, y_scores)\n",
    "    plt.figure()\n",
    "    plt.plot(rec_vals, prec_vals, color=PALETTE['accent'])\n",
    "    plt.xlabel(\"recall\"); plt.ylabel(\"precision\"); plt.title(\"precision recall curve\")\n",
    "    pdf.savefig(); plt.close()\n",
    "\n",
    "#showing how tpr/fpr/precision vary with threshold\n",
    "def plot_threshold_metrics(y_true, y_scores, pdf):\n",
    "    thresholds = np.linspace(0, 1, 100)\n",
    "    tprs, fprs, precs = [], [], []\n",
    "    for t in thresholds:\n",
    "        p = (y_scores >= t).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, p).ravel()\n",
    "        tprs.append(tp / (tp + fn) if tp + fn > 0 else 0)\n",
    "        fprs.append(fp / (fp + tn) if fp + tn > 0 else 0)\n",
    "        precs.append(precision_score(y_true, p, zero_division=0))\n",
    "    plt.figure()\n",
    "    plt.plot(thresholds, tprs, label=\"tpr\", color=PALETTE['dark'])\n",
    "    plt.plot(thresholds, fprs, label=\"fpr\", color=PALETTE['med'])\n",
    "    plt.plot(thresholds, precs, label=\"precision\", color=PALETTE['accent'])\n",
    "    plt.xlabel(\"threshold\"); plt.ylabel(\"rate\"); plt.title(\"threshold vs metrics\"); plt.legend()\n",
    "    pdf.savefig(); plt.close()\n",
    "\n",
    "#heatmap\n",
    "def plot_confusion_heatmap(y_true, y_pred, pdf):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cmap = sns.light_palette(PALETTE['dark'], as_cmap=True)\n",
    "    plt.figure()\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=cmap,\n",
    "                xticklabels=[\"benign\", \"attack\"],\n",
    "                yticklabels=[\"benign\", \"attack\"])\n",
    "    plt.title(\"confusion matrix\"); plt.xlabel(\"predicted\"); plt.ylabel(\"actual\")\n",
    "    pdf.savefig(); plt.close()\n",
    "\n",
    "#plot flow bytes/s over time\n",
    "def show_time_series(data, pdf):\n",
    "    if data.time_series is not None:\n",
    "        df = data.time_series.copy()\n",
    "        df['Timestamp'] = pd.to_datetime(df['Timestamp'], errors='coerce')\n",
    "        df = df.dropna().sort_values('Timestamp')\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(df['Timestamp'], df['Flow Bytes/s'], color=PALETTE['accent'])\n",
    "        plt.title(\"ddos behavior over time\"); plt.ylabel(\"flow bytes/s\"); plt.grid()\n",
    "        pdf.savefig(); plt.close()\n",
    "\n",
    "#drawing the netraph n highlighting suspicious nodes\n",
    "def show_graph_topology(data, pdf, scores=None, threshold=0.5, title=\"graph topology\"):\n",
    "    G = nx.Graph()\n",
    "    flows = data.raw_flows\n",
    "    G.add_edges_from(zip(flows['src'], flows['dst']))\n",
    "\n",
    "    if scores is not None:\n",
    "        color_map = []\n",
    "        for node in G:\n",
    "            s = scores[node] if node < len(scores) else 0\n",
    "            if s > threshold:\n",
    "                color_map.append('red')\n",
    "            elif s > 0.3:\n",
    "                color_map.append('orange')\n",
    "            else:\n",
    "                color_map.append('green')\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        nx.draw(G, node_color=color_map, with_labels=True, font_size=6, node_size=100)\n",
    "    else:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        nx.draw(G, node_color='brown', with_labels=True, font_size=6, node_size=100)\n",
    "\n",
    "    plt.title(title)\n",
    "    pdf.savefig(); plt.close()\n",
    "\n",
    "#getting mitigation actions where we decide to block/limit/sinkhole based on scores obtained\n",
    "def get_mitigation_actions(data, scores, threshold_blacklist=0.5, threshold_limit=(0.3, 0.5)):\n",
    "    actions = []\n",
    "    for nid, sc in enumerate(scores):\n",
    "        ip = data.node_ip_map.get(nid, f'node{nid}')\n",
    "        if sc > threshold_blacklist:\n",
    "            actions.append((ip, 'blacklist'))\n",
    "        elif threshold_limit[0] <= sc <= threshold_limit[1]:\n",
    "            actions.append((ip, 'rate limit 10mbps'))\n",
    "        elif sc > 0.8:\n",
    "            actions.append((ip, 'sinkhole'))\n",
    "    return actions\n",
    "\n",
    "#printing counts of unique source/dest IPs\n",
    "def check_unique_ips(df):\n",
    "    s = len(df['Source IP'].unique())\n",
    "    d = len(df['Destination IP'].unique())\n",
    "    a = len(pd.unique(df[['Source IP', 'Destination IP']].values.ravel()))\n",
    "    print(f\"unique ips in source ip       : {s}\")\n",
    "    print(f\"unique ips in dest ip         : {d}\")\n",
    "    print(f\"total unique ips              : {a}\")\n",
    "    return a\n",
    "\n",
    "#inject label noise method \n",
    "\n",
    "def inject_label_noise(df, flip_fraction=0.1, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    idxs = df[df['Label'] == 1].index\n",
    "    n_flip = int(len(idxs) * flip_fraction)\n",
    "    flips = np.random.choice(idxs, n_flip, replace=False)\n",
    "    df.loc[flips, 'Label'] = 0\n",
    "    return df\n",
    "    \n",
    "#datapath to file, one of the main parts \n",
    "\n",
    "data_dir = \"ddos\"\n",
    "all_attacks = [\n",
    "    \"DrDoS_DNS\", \"DrDoS_LDAP\", \"DrDoS_MSSQL\", \"DrDoS_NetBIOS\",\n",
    "    \"DrDoS_NTP\", \"DrDoS_SNMP\", \"DrDoS_SSDP\", \"DrDoS_UDP\",\n",
    "    \"Syn\", \"TFTP\", \"UDPLag\"\n",
    "]\n",
    "\n",
    "with PdfPages(\"visualizationrep.pdf\") as pdf:\n",
    "    for atk in all_attacks:\n",
    "        print(f\"\\n{atk}\\n\")\n",
    "        df = load_attack_type(data_dir, atk, nrows=100000, n_attacks=20, amount_of_noise=0.1)\n",
    "        check_unique_ips(df)\n",
    "        df = preprocess_for_graph(df)\n",
    "        df = inject_label_noise(df, flip_fraction=0.1)\n",
    "\n",
    "        #spliting into train/test flows\n",
    "        train_flows, test_flows = train_test_split(\n",
    "            df, test_size=0.3, stratify=df['Label'], random_state=42\n",
    "        )\n",
    "\n",
    "        train_data = build_graph(train_flows)\n",
    "        test_data = build_graph(test_flows)\n",
    "\n",
    "        #visualization before attack pre\n",
    "        show_graph_topology(train_data, pdf, title=f\"{atk}: pre atk topology\")\n",
    "        show_time_series(train_data, pdf)\n",
    "\n",
    "        #training and evaluating\n",
    "        model = train(train_data, epochs=50, hidden_channels=32)\n",
    "        y_true, y_scores, y_pred, acc, prec, rec, f1, tp, fp, tn, fn = evaluate_model(\n",
    "            model, test_data\n",
    "        )\n",
    "\n",
    "        #some performance plots\n",
    "        plot_roc_pr(y_true, y_scores, pdf)\n",
    "        plot_threshold_metrics(y_true, y_scores, pdf)\n",
    "        plot_confusion_heatmap(y_true, y_pred, pdf)\n",
    "        plot_feature_importance(model, train_data, pdf)\n",
    "\n",
    "        #post attck visualization\n",
    "        show_graph_topology(test_data, pdf, scores=y_scores, title=f\"{atk}: post atk topology\")\n",
    "\n",
    "        #summary\n",
    "        plt.figure()\n",
    "        plt.axis('off')\n",
    "        summary = (\n",
    "            f\"attack: {atk}\\n\\n\"\n",
    "            f\"accuracy: {acc:.4f}  precision: {prec:.4f}\\n\"\n",
    "            f\"recall: {rec:.4f}  f1: {f1:.4f}\\n\"\n",
    "            f\"tp: {tp}  fp: {fp}  tn: {tn}  fn: {fn}\"\n",
    "        )\n",
    "        plt.text(0, 0.5, summary, fontsize=12, fontfamily=\"monospace\")\n",
    "        pdf.savefig(); plt.close()\n",
    "\n",
    "        #mitigation actions\n",
    "        actions = get_mitigation_actions(test_data, y_scores)\n",
    "        print(\"\\nmitigation actions:\")\n",
    "        for ip, act in actions:\n",
    "            print(f\"{ip}: {act}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
